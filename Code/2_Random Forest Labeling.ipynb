{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(2021)\n",
    "\n",
    "# install if not installed already\n",
    "#!conda install gensim\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "#nltk.download('wordnet') #download if not present already\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in data\n",
    "# first our hand labeled data\n",
    "training_data = pd.read_csv(\"../Data/vader_sample_label.csv\")\n",
    "training_data = training_data.drop([\"Jakob\", \"Jamie\", \"Darren\", \"Agree w/ Vader\", \"Heather\"], axis=1)\n",
    "\n",
    "# our data that needs to be hand labaled\n",
    "data_to_label = pd.read_csv(\"../Data/vader_result_final.csv\")\n",
    "data_to_label = data_to_label.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing labels with numbers\n",
    "mapping_sentiment = {\"Positive\": 1, \"Negative\": 0}\n",
    "mapping_vaccine = {\"p\": 1, \"a\": 0, \"u\": 2}\n",
    "\n",
    "training_data = training_data.replace({\"assigned\": mapping_sentiment, \"Final Decision\": mapping_vaccine})\n",
    "\n",
    "data_to_label = data_to_label.replace({\"assigned\": mapping_sentiment})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping 2's (unknowns) and reindexing\n",
    "training_data = training_data[training_data[\"Final Decision\"] != 2]\n",
    "training_data = training_data.reset_index(drop = True)\n",
    "\n",
    "# unknowns should already be removed from data_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning functions\n",
    "\n",
    "def cleaning(text): # to remove mentions and links, taken partially from juejue's and jamie's notebooks\n",
    "    text = text.replace(\"\\\\n\", \" \") # dropping \\n\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text) # remove punctuation\n",
    "    text = re.sub('\\S*@\\S*\\s?', '',text) # remove emails\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ', text) # remove links\n",
    "    text = re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", '', text) # also removes links?\n",
    "    text = re.sub(r'\\d+', '', text) # remove numbers\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_stem(tweets, rawtweets = False): # cleaning and stemming\n",
    "    \n",
    "    if rawtweets == True:\n",
    "        # raw tweets pulled straight from Twitter\n",
    "        # clears the 'b and the ' at the start and end of the tweet\n",
    "        tweets = tweets.str[2:] # dropping first two characters apostrophe and b\n",
    "        tweets = tweets.str[:-1] # dropping last character apostrophe\n",
    "    \n",
    "    # removing punctuation, \\\\n, links, etc.\n",
    "    tweets = tweets.apply(cleaning)\n",
    "    \n",
    "    # stemming the words, also remove stop words\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    text = tweets.to_list()\n",
    "    process_tweets = []\n",
    "    \n",
    "    # adding common words to set of stopwords\n",
    "    new_stopwords = gensim.parsing.preprocessing.STOPWORDS.union(set([\"covid\", \"vaccine\", \"college\"]))\n",
    "\n",
    "    for sentence in text:\n",
    "        # iterate through each word in a tweet/sentence, if not part of stopwords list then keep in tweet\n",
    "        process_tweets.append(\" \".join([stemmer.stem(i) for i in sentence.split() if i not in new_stopwords]))\n",
    "    \n",
    "    #return list of cleaned tweets\n",
    "    return process_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a look at the training data\n",
    "#training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a look at the data that needs to be labeled\n",
    "#data_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined datasets\n",
    "combined_set = training_data.append(data_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_set[\"clean_text\"] = clean_stem(combined_set[\"text\"], rawtweets = False)\n",
    "#combined_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing duplicates and resetting index\n",
    "combined_set = combined_set.drop_duplicates(subset=[\"clean_text\"], keep='first') # remove any duplicate tweets\n",
    "combined_set = combined_set.reset_index(drop = True) # rest index\n",
    "\n",
    "# w/ duplicates removed, taking out the training data\n",
    "training_data = combined_set[~np.isnan(combined_set[\"Final Decision\"])] # removing NaN values\n",
    "#training_data # cleaned training data without duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing dtm, random forest classifier\n",
    "vectorizer = CountVectorizer(min_df=5) # min_df is minimum document frequency to include token/word\n",
    "rfc = RandomForestClassifier() # random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating feature matrix, the frequency term matrices\n",
    "dtm = vectorizer.fit_transform(combined_set[\"clean_text\"]).toarray() # matrix of all tweets\n",
    "training_dtm = dtm[0:len(training_data)] # features of only training data\n",
    "data_to_label_dtm = dtm[len(training_data):len(combined_set)] # features of data to be labeled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels pro/anti-vaccine\n",
    "training_labels = np.array(combined_set[\"Final Decision\"][0:len(training_data)]) # labels of training set\n",
    "rfc.fit(training_dtm, training_labels) # fitting training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting rest of the tweets\n",
    "label_pred = rfc.predict(data_to_label_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with predicted labels\n",
    "to_label_df = combined_set[np.isnan(combined_set[\"Final Decision\"])]\n",
    "to_label_df = to_label_df.reset_index(drop = True) # rest index\n",
    "to_label_df[\"Predicted Label\"] = label_pred.tolist()\n",
    "#to_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abc</th>\n",
       "      <th>abl</th>\n",
       "      <th>aborigin</th>\n",
       "      <th>abort</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolut</th>\n",
       "      <th>academ</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accid</th>\n",
       "      <th>...</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>your</th>\n",
       "      <th>youth</th>\n",
       "      <th>youv</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yup</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3223</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3224</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3226</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3227 rows × 1827 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abc  abl  aborigin  abort  abroad  absolut  academ  accept  access  \\\n",
       "0       0    0         0      0       0        0       0       0       0   \n",
       "1       0    0         0      0       0        0       0       0       0   \n",
       "2       0    0         0      0       0        0       0       0       0   \n",
       "3       0    0         0      0       0        0       0       0       0   \n",
       "4       0    0         0      0       0        0       0       0       0   \n",
       "...   ...  ...       ...    ...     ...      ...     ...     ...     ...   \n",
       "3222    0    0         0      0       0        0       0       0       0   \n",
       "3223    0    0         0      0       0        0       0       0       0   \n",
       "3224    0    0         0      0       0        0       0       0       0   \n",
       "3225    0    0         0      0       0        0       0       0       0   \n",
       "3226    0    0         0      0       0        0       0       0       0   \n",
       "\n",
       "      accid  ...  younger  youngest  your  youth  youv  yr  yrs  yup  zero  \\\n",
       "0         0  ...        0         0     0      0     0   0    0    0     0   \n",
       "1         0  ...        0         0     0      0     0   0    0    0     0   \n",
       "2         0  ...        0         0     0      0     0   0    0    0     0   \n",
       "3         0  ...        0         0     0      0     0   0    0    0     0   \n",
       "4         0  ...        0         0     0      0     0   0    0    0     0   \n",
       "...     ...  ...      ...       ...   ...    ...   ...  ..  ...  ...   ...   \n",
       "3222      0  ...        0         0     0      0     0   0    0    0     0   \n",
       "3223      0  ...        0         0     0      0     0   0    0    0     0   \n",
       "3224      0  ...        0         0     0      0     0   0    0    0     0   \n",
       "3225      0  ...        0         0     0      0     0   0    0    0     0   \n",
       "3226      0  ...        0         0     0      0     0   0    0    0     0   \n",
       "\n",
       "      zoom  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "...    ...  \n",
       "3222     0  \n",
       "3223     0  \n",
       "3224     0  \n",
       "3225     0  \n",
       "3226     0  \n",
       "\n",
       "[3227 rows x 1827 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting tokens for dtm\n",
    "tokens = vectorizer.get_feature_names() # our tokens, the words\n",
    "\n",
    "#tokens = np.asarray(tokens).reshape(1, len(tokens)) # converting list to numpy array\n",
    "#tweet_dtm = np.append(tokens, data_to_label_dtm, axis = 0)\n",
    "\n",
    "# dataframe with tokens as column names\n",
    "tokens = vectorizer.get_feature_names() # our tokens, the words\n",
    "tweet_df = pd.DataFrame(data_to_label_dtm, columns = tokens) # creating dataframe\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>assigned</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Predicted Label</th>\n",
       "      <th>abc</th>\n",
       "      <th>abl</th>\n",
       "      <th>aborigin</th>\n",
       "      <th>abort</th>\n",
       "      <th>...</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>your</th>\n",
       "      <th>youth</th>\n",
       "      <th>youv</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yup</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If a college forces the vaccine, they should ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>if forc su exist wreck fraud deliber withhold ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My Deans List Sophomore unwelcome at her coll...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>my dean list sophomor unwelcom w o covid she r...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>are you paying out if your personal pocket fo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>pay person pocket scholarship gave away peopl ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>please help my daughter in #NJ () return to c...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>help daughter nj return shes declin recov campus</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deathsantis say vaccine cards are wrong.. But ...</td>\n",
       "      <td>0.652439</td>\n",
       "      <td>0.347561</td>\n",
       "      <td>1</td>\n",
       "      <td>deathsanti card wrong but mandat parti affili ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>Getting your COVID-19 vaccine will help protec...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>get covid help protect famili friend colleg co...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3223</th>\n",
       "      <td>Virologists are worried by the way vaccines ar...</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0</td>\n",
       "      <td>virologist worri way vaccin prevent ill peopl ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3224</th>\n",
       "      <td>Many physicians recommend the jab because t...</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.253521</td>\n",
       "      <td>1</td>\n",
       "      <td>mani physician recommend jab financi incent or...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225</th>\n",
       "      <td>The fear factor will never end.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>the fear factor end</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3226</th>\n",
       "      <td>How College CVD Vaccine Mandates Put Students ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>how colleg cvd vaccin mandat put student in da...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3227 rows × 1833 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  positive  negative  \\\n",
       "0      If a college forces the vaccine, they should ...  0.000000  1.000000   \n",
       "1      My Deans List Sophomore unwelcome at her coll...  0.500000  0.500000   \n",
       "2      are you paying out if your personal pocket fo...  0.000000  1.000000   \n",
       "3      please help my daughter in #NJ () return to c...  1.000000  0.000000   \n",
       "4     Deathsantis say vaccine cards are wrong.. But ...  0.652439  0.347561   \n",
       "...                                                 ...       ...       ...   \n",
       "3222  Getting your COVID-19 vaccine will help protec...  1.000000  0.000000   \n",
       "3223  Virologists are worried by the way vaccines ar...  0.309091  0.690909   \n",
       "3224     Many physicians recommend the jab because t...  0.746479  0.253521   \n",
       "3225                   The fear factor will never end.   0.000000  1.000000   \n",
       "3226  How College CVD Vaccine Mandates Put Students ...  0.000000  1.000000   \n",
       "\n",
       "      assigned                                         clean_text  \\\n",
       "0            0  if forc su exist wreck fraud deliber withhold ...   \n",
       "1            0  my dean list sophomor unwelcom w o covid she r...   \n",
       "2            0  pay person pocket scholarship gave away peopl ...   \n",
       "3            1   help daughter nj return shes declin recov campus   \n",
       "4            1  deathsanti card wrong but mandat parti affili ...   \n",
       "...        ...                                                ...   \n",
       "3222         1  get covid help protect famili friend colleg co...   \n",
       "3223         0  virologist worri way vaccin prevent ill peopl ...   \n",
       "3224         1  mani physician recommend jab financi incent or...   \n",
       "3225         0                                the fear factor end   \n",
       "3226         0  how colleg cvd vaccin mandat put student in da...   \n",
       "\n",
       "      Predicted Label  abc  abl  aborigin  abort  ...  younger  youngest  \\\n",
       "0                 0.0    0    0         0      0  ...        0         0   \n",
       "1                 1.0    0    0         0      0  ...        0         0   \n",
       "2                 1.0    0    0         0      0  ...        0         0   \n",
       "3                 1.0    0    0         0      0  ...        0         0   \n",
       "4                 0.0    0    0         0      0  ...        0         0   \n",
       "...               ...  ...  ...       ...    ...  ...      ...       ...   \n",
       "3222              1.0    0    0         0      0  ...        0         0   \n",
       "3223              1.0    0    0         0      0  ...        0         0   \n",
       "3224              0.0    0    0         0      0  ...        0         0   \n",
       "3225              1.0    0    0         0      0  ...        0         0   \n",
       "3226              0.0    0    0         0      0  ...        0         0   \n",
       "\n",
       "      your  youth  youv  yr  yrs  yup  zero  zoom  \n",
       "0        0      0     0   0    0    0     0     0  \n",
       "1        0      0     0   0    0    0     0     0  \n",
       "2        0      0     0   0    0    0     0     0  \n",
       "3        0      0     0   0    0    0     0     0  \n",
       "4        0      0     0   0    0    0     0     0  \n",
       "...    ...    ...   ...  ..  ...  ...   ...   ...  \n",
       "3222     0      0     0   0    0    0     0     0  \n",
       "3223     0      0     0   0    0    0     0     0  \n",
       "3224     0      0     0   0    0    0     0     0  \n",
       "3225     0      0     0   0    0    0     0     0  \n",
       "3226     0      0     0   0    0    0     0     0  \n",
       "\n",
       "[3227 rows x 1833 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final dataframe with the tweets, sentiments, predicted labels, and the dtm\n",
    "\n",
    "final_df = pd.concat([to_label_df, tweet_df], axis = 1) # combine predicted label dataframe and dtm dataframe\n",
    "final_df = final_df.drop([\"Final Decision\"], axis=1)\n",
    "final_df.to_csv(\"../Data/tweet_dtm.csv\", sep = \",\", index=False)\n",
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
